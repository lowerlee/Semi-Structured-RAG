{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !brew list\n",
    "# !pip show langchain\n",
    "# !pip show chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import pickle\n",
    "from pydantic import BaseModel\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"2020-Democratic-Citizenship_Our-Common-Purpose.pdf\"\n",
    "\n",
    "# Get elements\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=path,\n",
    "    # Unstructured first finds embedded image blocks\n",
    "    extract_images_in_pdf=False,\n",
    "    # Use layout model (YOLOX) to get bounding boxes (for tables) and find titles\n",
    "    # Titles are any sub-section of the document\n",
    "    infer_table_structure=True,\n",
    "    # Post processing to aggregate text once we have the title\n",
    "    chunking_strategy=\"by_title\",\n",
    "    # Chunking params to aggregate text blocks\n",
    "    # Attempt to create a new chunk 3800 chars\n",
    "    # Attempt to keep chunks > 2000 chars\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=path,\n",
    ")\n",
    "\n",
    "# Specify the directory and the filename for the pickle file\n",
    "output_file_path = \"/workspaces/Semi-structured-RAG/pickles/raw_pdf_elements.pkl\"\n",
    "\n",
    "with open(output_file_path, \"wb\") as file:\n",
    "    pickle.dump(raw_pdf_elements, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the path to your pickle file\n",
    "pickle_file_path = \"/workspaces/Semi-structured-RAG/pickles/raw_pdf_elements.pkl\"\n",
    "\n",
    "# Using a 'with' statement ensures the file is properly closed after reading\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    # Load the data from the file\n",
    "    raw_pdf_elements = pickle.load(file)\n",
    "\n",
    "# Now you can use the 'data' variable which contains your deserialized object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in raw_pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Element(BaseModel):\n",
    "    type: str\n",
    "    text: Any\n",
    "\n",
    "\n",
    "# Categorize by type\n",
    "categorized_elements = []\n",
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "        categorized_elements.append(Element(type=\"table\", text=str(element)))\n",
    "    elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "        categorized_elements.append(Element(type=\"text\", text=str(element)))\n",
    "\n",
    "# Tables\n",
    "table_elements = [e for e in categorized_elements if e.type == \"table\"]\n",
    "print(len(table_elements))\n",
    "\n",
    "# Text\n",
    "text_elements = [e for e in categorized_elements if e.type == \"text\"]\n",
    "print(len(text_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text. \\ \n",
    "Give a concise summary of the table or text. Table or text chunk: {element} \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "# Summary chain\n",
    "model = ChatOpenAI(temperature=0, openai_api_base=\"http://host.docker.internal:1234/v1\", openai_api_key=\"dummy_key\")\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table_elements' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply to tables\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tables \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtable_elements\u001b[49m]\n\u001b[1;32m      3\u001b[0m table_summaries \u001b[38;5;241m=\u001b[39m summarize_chain\u001b[38;5;241m.\u001b[39mbatch(tables, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_concurrency\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m})\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Apply to texts\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'table_elements' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply to tables\n",
    "tables = [i.text for i in table_elements]\n",
    "table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 5})\n",
    "\n",
    "# Apply to texts\n",
    "texts = [i.text for i in text_elements]\n",
    "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 5})\n",
    "\n",
    "# Adding summaries to a dictionary\n",
    "summaries = {\n",
    "    \"table_summaries\": table_summaries,\n",
    "    \"tables\": tables,\n",
    "    \"text_summaries\": text_summaries,\n",
    "    \"texts\": texts\n",
    "}\n",
    "\n",
    "# Specify the directory and the filename for the pickle file\n",
    "summaries_file_path = \"/workspaces/Semi-structured-RAG/pickles/summaries.pkl\"\n",
    "\n",
    "with open(summaries_file_path, \"wb\") as file:\n",
    "    pickle.dump(summaries, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the path to your pickle file\n",
    "pickle_file_path = \"/workspaces/Semi-structured-RAG/pickles/summaries.pkl\"\n",
    "\n",
    "# Using a 'with' statement ensures the file is properly closed after reading\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    # Load the data from the file\n",
    "    summaries = pickle.load(file)\n",
    "\n",
    "# Now you can use the 'data' variable which contains your deserialized object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "# The vectorstore to use to index the child chunks\n",
    "vectorstore = Chroma(collection_name=\"summaries\", embedding_function=OllamaEmbeddings(model=\"llama2\", base_url='http://host.docker.internal:11434'))\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# The retriever (empty to start)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# Add texts\n",
    "doc_ids = [str(uuid.uuid4()) for _ in summaries.get(\"text\")]\n",
    "summary_texts = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries.get(\"text_summaries\"))\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_texts)\n",
    "retriever.docstore.mset(list(zip(doc_ids, summaries.get(\"text\"))))\n",
    "\n",
    "# Add tables\n",
    "table_ids = [str(uuid.uuid4()) for _ in summaries.get(\"tables\")]\n",
    "summary_tables = [\n",
    "    Document(page_content=s, metadata={id_key: table_ids[i]})\n",
    "    for i, s in enumerate(summaries.get(\"table_summaries\"))\n",
    "]\n",
    "retriever.vectorstore.add_documents(summary_tables)\n",
    "retriever.docstore.mset(list(zip(table_ids, summaries.get(\"tables\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Prompt template\n",
    "template = \"\"\"Answer the question based only on the following context, which can include text and tables:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(temperature=0, openai_api_base=\"http://host.docker.internal:1234/v1\", openai_api_key=\"dummy_key\")\n",
    "\n",
    "# RAG pipeline\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Our Common Purpose document recommends several policies to reduce the influence of money in politics, give weight to a wider range of voices, and increase the legitimacy of our institutions. These recommendations include:\\n\\n1. Campaign finance reform: The report suggests that campaign finance laws should be updated to limit the role of large donors and special interest groups in political campaigns. This could include measures such as limiting the amount of money that can be spent on campaigns, requiring disclosure of donations, and prohibiting foreign interference in U.S. elections.\\n2. Ranked-choice voting: The report recommends implementing ranked-choice voting systems in federal and state elections to encourage more civil and issue-based campaigns. This system would allow voters to rank their preferences for multiple candidates, rather than just choosing between two candidates.\\n3. Voter education and outreach: The report suggests that voter education and outreach efforts should be increased to help people understand the importance of voting and how to participate in the democratic process. This could include initiatives such as voter registration drives, early voting, and online voter guides.\\n4. Independent redistricting commissions: The report recommends establishing independent redistricting commissions to draw district boundaries for elections. This would help ensure that districts are fairly represented and not manipulated by political parties or special interest groups.\\n5. Citizen-initiated referendums: The report suggests that citizen-initiated referendums should be allowed in certain states or localities to give citizens a direct say in policy decisions. This would allow people to have more control over the issues that affect their lives and increase trust in the democratic process.\\n6. Electoral reform: The report recommends exploring electoral reform options such as ranked-choice voting, proportional representation, and abolition of the electoral college to make the political system more representative and responsive to the will of the people.\\n7. Media literacy education: The report suggests that media literacy education should be included in school curricula to help students understand how to critically evaluate information and distinguish between fact and fiction. This would help combat the spread of misinformation and increase trust in the democratic process.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What are the recommendations from the Our Common Purpose document?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
